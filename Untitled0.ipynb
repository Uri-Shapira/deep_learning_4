{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbI474V3FVSstuGzuSfTsg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uri-Shapira/deep_learning_4/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRQAQ1-LcNUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWvq_jeScZFu",
        "colab_type": "code",
        "outputId": "a34257ab-0c18-4c9c-f5f2-eada327c7062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transforms.ToTensor())\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transforms.ToTensor())\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6hI6kXRcrkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plane = trainset.class_to_idx['airplane']\n",
        "frog = trainset.class_to_idx['frog']\n",
        "\n",
        "def filter_plane_frog_classes(images):\n",
        "  result = []\n",
        "  for idx, x in enumerate(images):\n",
        "    arr, target = x\n",
        "    if (target == plane) or (target == frog):\n",
        "      result.append(idx)\n",
        "  return result\n",
        "\n",
        "frog_plane_trainset = torch.utils.data.Subset(trainset, filter_plane_frog_classes(trainset))\n",
        "frog_plane_testset = torch.utils.data.Subset(testset, filter_plane_frog_classes(testset))\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(frog_plane_trainset, batch_size=32,\n",
        "                                          shuffle=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(frog_plane_testset, batch_size=32,\n",
        "                                         shuffle=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ilwqi_KPcuS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        # now a few fully connected layers\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32zCpBPccw42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################\n",
        "#########   DEFINE OPTIMIZERS ##########################\n",
        "########################################################\n",
        "class MyOptimizer:\n",
        "\n",
        "    def __init__(self, parameters):\n",
        "        self.parameters = parameters\n",
        "        self.learning_rate = 0.001\n",
        "        self.param_groups = []\n",
        "        param_groups = list(self.parameters)\n",
        "        if not isinstance(param_groups[0], dict):\n",
        "            param_groups = [{'params': param_groups}]\n",
        "        for param_group in param_groups:\n",
        "            self.add_param_group(param_group)\n",
        "\n",
        "    def add_param_group(self, param_group):\n",
        "        params = param_group['params']\n",
        "        if isinstance(params, torch.Tensor):\n",
        "            param_group['params'] = [params]\n",
        "        else:\n",
        "            param_group['params'] = list(params)\n",
        "        param_set = set()\n",
        "        for group in self.param_groups:\n",
        "            param_set.update(set(group['params']))\n",
        "        self.param_groups.append(param_group)\n",
        "  \n",
        "    def zero_grad(self):\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is not None:\n",
        "                    p.grad.detach_()\n",
        "                    p.grad.zero_()\n",
        "    def step(self):\n",
        "      raise NotImplementedError\n",
        "\n",
        "class sgd(MyOptimizer):\n",
        "\n",
        "    def __init__(self, parameters):\n",
        "        MyOptimizer.__init__(self,parameters)\n",
        "\n",
        "    def step(self):\n",
        "        for group in self.param_groups:\n",
        "            params = group['params']\n",
        "            for p in params:\n",
        "                if p.grad is None:\n",
        "                    print('none')\n",
        "                    continue\n",
        "                dp = p.grad.data\n",
        "                p.data = p.data.add(-self.learning_rate, dp)\n",
        "\n",
        "class SGD_with_momentum(MyOptimizer):\n",
        "    \n",
        "    def __init__(self, parameters):\n",
        "        self.momentum = 0.5\n",
        "        self.beta = 0.01 \n",
        "        MyOptimizer.__init__(self,parameters)\n",
        "    \n",
        "    def step(self):\n",
        "        v = 0\n",
        "        for group in self.param_groups:\n",
        "            params = group['params']\n",
        "            for p in params:\n",
        "                if p.grad is None:\n",
        "                    print('none')\n",
        "                    continue\n",
        "                dp = p.grad.data\n",
        "                if self.momentum != 0:\n",
        "                    buf = torch.clone(dp).detach()\n",
        "                    buf.mul_(self.momentum).add_(1 - self.beta, dp)\n",
        "                p.data = p.data.add(-self.learning_rate, dp)\n",
        "\n",
        "class ADAM(MyOptimizer):\n",
        "\n",
        "  def __init__(self, parameters):\n",
        "      MyOptimizer.__init__(self,parameters)\n",
        "      self.v = None\n",
        "      self.gi = None\n",
        "      self.momentum = 0.5\n",
        "      self.epsilon = 0.00000001\n",
        "      self.min_lr_list = []\n",
        "      self.max_lr_list = []\n",
        "\n",
        "  def step(self):\n",
        "        minlr = np.Infinity\n",
        "        maxlr = 0\n",
        "        for group in self.param_groups:\n",
        "            params = group['params']\n",
        "            if self.v is None:\n",
        "                self.v = [None for i in params]\n",
        "            if self.gi is None:\n",
        "                self.gi = [None for i in params]\n",
        "            for i, p in enumerate(params):\n",
        "                if p.grad is None:\n",
        "                    print('none')\n",
        "                    continue\n",
        "                dp = p.grad.data\n",
        "                if self.gi[i] is None:\n",
        "                    self.gi[i] = torch.zeros_like(dp)\n",
        "                if self.v[i] is None:\n",
        "                    self.v[i] = dp.clone().detach()\n",
        "                else:\n",
        "                    self.v[i] = self.v[i] * self.momentum + (1 - self.momentum) * dp\n",
        "                b = 0.999\n",
        "                self.gi[i] = b * self.gi[i] + (1 - b) * (dp ** 2)\n",
        "                temp = self.v[i] / torch.sqrt(self.gi[i] + self.epsilon)\n",
        "                print(\"=====================================\")\n",
        "                print(temp)\n",
        "                if torch.clamp(temp,max=value) > maxlr:\n",
        "                  maxlr = torch.clamp(temp,max=value)\n",
        "                if torch.clamp(temp,min=value) < minlr:\n",
        "                  minlr = torch.clamp(temp,min=value)\n",
        "                p.data = p.data.add(-self.learning_rate, self.v[i] / torch.sqrt(self.gi[i] + self.epsilon))\n",
        "        self.min_lr_list.append(minlr) \n",
        "        self.max_lr_list.append(maxlr)\n",
        "\n",
        "class RMSProp(MyOptimizer):\n",
        "\n",
        "    def __init__(self, parameters):\n",
        "        MyOptimizer.__init__(self,parameters)\n",
        "        self.beta = 0.01\n",
        "\n",
        "    def step(self):\n",
        "        for group in self.param_groups:\n",
        "          params = group['params']\n",
        "          if self.beta is None:\n",
        "            self.beta = [None for i in params]\n",
        "          if self.gi is None:\n",
        "            self.gi = [None for i in params]\n",
        "          for i, p in enumerate(params):\n",
        "            if p.grad is None:\n",
        "              print('none')\n",
        "              continue\n",
        "            dp = p.grad.data\n",
        "            if self.gi[i] is None:\n",
        "              self.gi[i] = torch.zeros_like(dp)\n",
        "            self.gi[i] = self.beta * self.g[i] + (1 - self.beta) * (dp ** 2)\n",
        "            p.data = p.data.add(-self.learning_rate*dp/np.sqrt(self.gi[i]+self.epsilon))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvxRZDo-c26O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################\n",
        "#########   TRAIN             ##########################\n",
        "########################################################\n",
        "def get_test_loss(net):\n",
        "    test_loss = 0.0\n",
        "    for i, data in enumerate(testloader, 0):\n",
        "        inputs, labels = data\n",
        "        outputs = net(inputs)\n",
        "        current_loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "        test_loss += current_loss.item()\n",
        "    return test_loss / (i + 1)\n",
        "\n",
        "def get_optimizer_type(step_name, parameters):\n",
        "    optimizer = None\n",
        "    if step_name == 'sgd':\n",
        "        optimizer = sgd(parameters)\n",
        "    elif step_name == 'sgd_with_momentum':\n",
        "        optimizer = SGD_with_momentum(parameters)\n",
        "    elif step_name == 'adam':\n",
        "        optimizer = ADAM(parameters)\n",
        "    else:\n",
        "        optimizer = RMSProp(parameters)\n",
        "    return optimizer\n",
        "\n",
        "def train(net, trainloader, step_name, num_of_epochs=100):\n",
        "    # define loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # define the optimizer\n",
        "    optimizer = get_optimizer_type(step_name, net.parameters())\n",
        "    loss_train = []\n",
        "    loss_test = []\n",
        "    for epoch in range(num_of_epochs):\n",
        "        epoch_loss_sum = 0.0\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "          # will run optimizer based on step_name parameter\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            curr_loss = loss.item()\n",
        "            running_loss += curr_loss\n",
        "            epoch_loss_sum += curr_loss\n",
        "            if i % 200 == 0:\n",
        "                print('[%d, %5d] Train Loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 200.0))\n",
        "                running_loss = 0.0\n",
        "        current_test_loss = get_test_loss(net)\n",
        "        print('[%d] Test Loss: %.3f' %(epoch + 1, current_test_loss))\n",
        "        loss_train.append(epoch_loss_sum / len(trainloader))\n",
        "        loss_test.append(current_test_loss)\n",
        "\n",
        "    print('Finished Training')\n",
        "    return loss_train, loss_test, optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVXha5sCdF8y",
        "colab_type": "code",
        "outputId": "7b738b38-870e-48de-c2d6-1da56dde74d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##### CREATE NETWORKS AND TRAIN WITH 4 OPTIMIZERS\n",
        "\n",
        "net = CNN()\n",
        "adam_loss_train, adam_loss_test, adam_optimizer = train(net, trainloader, 'adam')\n",
        "\n",
        "sgd_net = CNN()\n",
        "sgd_loss_train, sgd_loss_test, sgd_optimizer = train(sgd_net, trainloader, 'sgd')\n",
        "\n",
        "sgd_momentum_net = CNN()\n",
        "sgd_momentum_loss_train, sgd_momentum_loss_test, sgd_momentum_optimzer = train(sgd_momentum_net, trainloader, 'SGD_with_momentum')\n",
        "\n",
        "RMS_net = CNN()\n",
        "RMSProp_loss_train, RMSProp_loss_test = train(RMS_net, trainloader, 'RMSProp')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=====================================\n",
            "tensor([[[[ 8.5946e+00,  9.2442e+00,  1.0215e+01,  1.4257e+01,  1.6192e+01],\n",
            "          [ 1.6109e+01,  1.3366e+01,  1.0272e+01,  1.2012e+01,  1.4370e+01],\n",
            "          [ 1.6483e+01,  1.2299e+01,  1.1718e+01,  1.1326e+01,  1.1913e+01],\n",
            "          [ 1.3318e+01,  1.3298e+01,  1.1841e+01,  1.2547e+01,  1.0656e+01],\n",
            "          [ 9.9161e+00,  1.2388e+01,  1.2041e+01,  1.0561e+01,  7.2751e+00]],\n",
            "\n",
            "         [[ 3.8865e+00,  5.8877e+00,  8.0303e+00,  1.2629e+01,  1.4505e+01],\n",
            "          [ 1.2063e+01,  9.5693e+00,  6.8227e+00,  9.2776e+00,  1.2270e+01],\n",
            "          [ 1.2168e+01,  7.0912e+00,  7.1365e+00,  7.6016e+00,  8.4138e+00],\n",
            "          [ 9.6440e+00,  8.4372e+00,  7.0599e+00,  8.6905e+00,  6.5438e+00],\n",
            "          [ 7.0004e+00,  8.1742e+00,  7.2559e+00,  6.4825e+00,  2.9240e+00]],\n",
            "\n",
            "         [[ 2.5693e-01,  3.1410e+00,  4.6688e+00,  9.6805e+00,  1.1589e+01],\n",
            "          [ 7.2190e+00,  6.1406e+00,  2.8966e+00,  6.0975e+00,  1.0359e+01],\n",
            "          [ 7.8997e+00,  4.4055e+00,  4.1840e+00,  4.4951e+00,  7.6124e+00],\n",
            "          [ 6.2193e+00,  6.5387e+00,  6.2793e+00,  7.3623e+00,  6.4718e+00],\n",
            "          [ 4.7684e+00,  7.5637e+00,  8.5593e+00,  7.6852e+00,  4.3226e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0082e+01,  1.0888e+01,  7.3048e+00,  3.1067e+00,  2.6434e+00],\n",
            "          [ 7.6815e+00,  9.0431e+00,  7.2259e+00,  3.7637e+00,  1.6417e+00],\n",
            "          [ 7.1478e+00,  7.9176e+00,  7.1431e+00,  5.2394e+00,  4.9906e+00],\n",
            "          [ 9.8650e+00,  8.9425e+00,  8.3186e+00,  8.0364e+00,  8.7938e+00],\n",
            "          [ 1.0327e+01,  8.3821e+00,  8.9268e+00,  9.7141e+00,  8.5948e+00]],\n",
            "\n",
            "         [[ 8.9048e+00,  9.5850e+00,  6.2462e+00,  2.7892e+00,  2.8242e+00],\n",
            "          [ 6.1634e+00,  7.6458e+00,  6.3074e+00,  3.1865e+00,  1.3405e+00],\n",
            "          [ 5.1706e+00,  6.2031e+00,  6.2695e+00,  4.6731e+00,  4.9427e+00],\n",
            "          [ 8.2311e+00,  7.2813e+00,  7.1851e+00,  7.3841e+00,  8.9159e+00],\n",
            "          [ 9.4094e+00,  7.0989e+00,  7.8807e+00,  9.1568e+00,  8.6231e+00]],\n",
            "\n",
            "         [[ 2.2734e+00,  2.9506e+00,  1.8887e+00,  4.7598e-01,  1.0453e+00],\n",
            "          [ 7.7781e-01,  1.7169e+00,  1.2646e+00,  3.4866e-01, -4.5763e-01],\n",
            "          [ 1.1468e+00,  1.8099e+00,  1.2436e+00,  8.2836e-01,  1.6845e+00],\n",
            "          [ 4.0880e+00,  3.4152e+00,  3.0225e+00,  3.6041e+00,  5.4831e+00],\n",
            "          [ 5.0050e+00,  3.3317e+00,  4.1859e+00,  5.8279e+00,  5.8767e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 5.1458e+00,  4.5733e+00,  5.4486e+00,  8.0173e+00,  1.0155e+01],\n",
            "          [ 5.9838e+00,  4.5115e+00,  8.0491e+00,  1.2478e+01,  1.4253e+01],\n",
            "          [ 4.9096e+00,  7.0204e+00,  1.0847e+01,  1.5155e+01,  1.6664e+01],\n",
            "          [ 9.7269e+00,  1.2625e+01,  1.2030e+01,  1.1864e+01,  1.5197e+01],\n",
            "          [ 1.3127e+01,  1.3881e+01,  1.3755e+01,  1.2614e+01,  1.1680e+01]],\n",
            "\n",
            "         [[ 7.2483e+00,  5.3970e+00,  6.0150e+00,  8.7475e+00,  1.1123e+01],\n",
            "          [ 8.0931e+00,  4.9881e+00,  7.6492e+00,  1.2261e+01,  1.4028e+01],\n",
            "          [ 7.4086e+00,  7.9730e+00,  1.0591e+01,  1.4817e+01,  1.6286e+01],\n",
            "          [ 1.1606e+01,  1.3636e+01,  1.2129e+01,  1.1101e+01,  1.3830e+01],\n",
            "          [ 1.3798e+01,  1.4609e+01,  1.4148e+01,  1.1546e+01,  8.6822e+00]],\n",
            "\n",
            "         [[ 1.3350e+01,  1.1282e+01,  1.0460e+01,  1.3181e+01,  1.5802e+01],\n",
            "          [ 1.3050e+01,  1.0377e+01,  1.1986e+01,  1.6154e+01,  1.7925e+01],\n",
            "          [ 1.1026e+01,  1.1845e+01,  1.4805e+01,  1.7936e+01,  1.9322e+01],\n",
            "          [ 1.4167e+01,  1.6634e+01,  1.6282e+01,  1.5653e+01,  1.7575e+01],\n",
            "          [ 1.6335e+01,  1.7698e+01,  1.7898e+01,  1.5899e+01,  1.2932e+01]]],\n",
            "\n",
            "\n",
            "        [[[-2.6952e+01, -2.7871e+01, -2.7684e+01, -2.7539e+01, -2.7875e+01],\n",
            "          [-2.7931e+01, -2.7995e+01, -2.7374e+01, -2.7457e+01, -2.8173e+01],\n",
            "          [-2.8281e+01, -2.8257e+01, -2.7651e+01, -2.7940e+01, -2.8225e+01],\n",
            "          [-2.8011e+01, -2.8132e+01, -2.8006e+01, -2.7957e+01, -2.7868e+01],\n",
            "          [-2.7529e+01, -2.7890e+01, -2.8027e+01, -2.8071e+01, -2.8117e+01]],\n",
            "\n",
            "         [[-2.4754e+01, -2.6153e+01, -2.5587e+01, -2.5394e+01, -2.5812e+01],\n",
            "          [-2.6321e+01, -2.6310e+01, -2.4909e+01, -2.4846e+01, -2.6263e+01],\n",
            "          [-2.7101e+01, -2.6903e+01, -2.5498e+01, -2.5720e+01, -2.6322e+01],\n",
            "          [-2.6930e+01, -2.6744e+01, -2.6187e+01, -2.6101e+01, -2.5961e+01],\n",
            "          [-2.6509e+01, -2.6595e+01, -2.6354e+01, -2.6441e+01, -2.6585e+01]],\n",
            "\n",
            "         [[-2.2853e+01, -2.4849e+01, -2.3784e+01, -2.3046e+01, -2.3688e+01],\n",
            "          [-2.4549e+01, -2.4821e+01, -2.3100e+01, -2.2894e+01, -2.4391e+01],\n",
            "          [-2.5475e+01, -2.5585e+01, -2.4130e+01, -2.4267e+01, -2.4558e+01],\n",
            "          [-2.5174e+01, -2.5320e+01, -2.4954e+01, -2.4535e+01, -2.3909e+01],\n",
            "          [-2.4403e+01, -2.4893e+01, -2.4901e+01, -2.4729e+01, -2.4575e+01]]],\n",
            "\n",
            "\n",
            "        [[[-1.0600e+00, -1.7822e+00, -5.5973e+00, -8.5047e+00, -8.8182e+00],\n",
            "          [ 1.0828e+00, -1.1900e+00, -5.2060e+00, -5.6240e+00, -3.2143e+00],\n",
            "          [ 2.1626e+00,  2.2622e+00, -1.8989e+00, -2.1882e-01, -2.8968e+00],\n",
            "          [ 8.2249e-01,  2.6902e+00,  1.6798e+00, -2.1817e+00, -5.4637e+00],\n",
            "          [-4.7707e-01,  8.2370e-02,  7.2400e-01, -4.0998e+00, -5.7551e+00]],\n",
            "\n",
            "         [[ 2.5241e+00,  2.0176e+00, -9.4357e-01, -3.6563e+00, -4.6951e+00],\n",
            "          [ 5.2781e+00,  3.5174e+00, -5.0606e-01, -1.5789e+00,  7.0939e-01],\n",
            "          [ 6.6357e+00,  7.3293e+00,  2.2513e+00,  2.4236e+00, -2.8539e-01],\n",
            "          [ 4.9774e+00,  7.4810e+00,  5.1113e+00, -4.1437e-01, -3.7267e+00],\n",
            "          [ 3.1241e+00,  4.1404e+00,  3.5777e+00, -2.4667e+00, -4.3168e+00]],\n",
            "\n",
            "         [[ 2.3639e+00,  1.9595e+00, -2.5374e-02, -2.1160e+00, -2.4932e+00],\n",
            "          [ 4.4245e+00,  2.6169e+00,  4.6512e-02, -2.8931e-01,  1.4232e+00],\n",
            "          [ 5.0608e+00,  5.3287e+00,  2.5079e+00,  3.4976e+00,  1.1301e-01],\n",
            "          [ 3.4951e+00,  6.0945e+00,  5.0156e+00,  8.4795e-01, -2.1956e+00],\n",
            "          [ 2.6253e+00,  4.0469e+00,  3.6089e+00, -1.3981e+00, -1.7003e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4491e+00,  1.8933e+00,  1.9846e+00,  2.7822e+00,  3.6560e+00],\n",
            "          [ 3.2608e+00,  2.6078e+00,  2.0077e+00,  2.4838e+00,  3.4404e+00],\n",
            "          [ 2.3254e+00,  1.2029e+00,  9.1533e-01,  1.0806e+00,  1.5607e+00],\n",
            "          [ 1.6338e+00,  4.1212e-01,  5.0434e-01,  7.9066e-01,  9.0251e-01],\n",
            "          [ 1.7092e+00,  6.9493e-01,  3.0420e-01,  9.8382e-02, -1.2469e-01]],\n",
            "\n",
            "         [[ 2.1028e+00,  1.5052e+00,  1.4272e+00,  1.8368e+00,  2.6153e+00],\n",
            "          [ 2.9032e+00,  2.2786e+00,  1.5619e+00,  1.7767e+00,  2.6696e+00],\n",
            "          [ 2.0632e+00,  9.9134e-01,  5.8293e-01,  6.4018e-01,  1.2019e+00],\n",
            "          [ 1.3723e+00,  2.5465e-01,  2.5028e-01,  5.2765e-01,  6.4728e-01],\n",
            "          [ 1.3580e+00,  3.6799e-01, -2.1600e-02, -1.6936e-01, -3.8353e-01]],\n",
            "\n",
            "         [[ 4.2525e-01, -2.1254e-01, -3.3591e-01, -3.6333e-02,  7.4610e-01],\n",
            "          [ 1.5229e+00,  1.1457e+00,  4.3111e-01,  2.3828e-01,  9.6319e-01],\n",
            "          [ 1.1494e+00,  4.8357e-01,  2.0429e-01, -1.3923e-01,  1.1817e-01],\n",
            "          [ 8.0316e-01,  1.1893e-01,  1.4402e-01,  1.6846e-01,  8.2304e-02],\n",
            "          [ 6.2720e-01,  1.9464e-01, -7.0342e-02, -3.9782e-01, -7.2093e-01]]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-f1ea87777d67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0madam_loss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_loss_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msgd_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-f10d331c41ab>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, step_name, num_of_epochs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0;31m# will run optimizer based on step_name parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-af43b4bbe9b4>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=====================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                   \u001b[0mmaxlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mminlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'value' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVlCOtV6laVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(sgd_loss_train, label=\"sgd loss train\")\n",
        "plt.plot(sgd_loss_test, label=\"sgd loss test\")\n",
        "plt.plot(sgd_momentum_loss_train, label=\"sgd momentum loss train\")\n",
        "plt.plot(sgd_momentum_loss_test, label=\"sgd momentum loss test\")\n",
        "plt.plot(adam_loss_train, label=\"adam loss train\")\n",
        "plt.plot(adam_loss_test, label=\"adam loss test\")\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuU0IdPDazFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(adam_optimizer.min_step_list,label=\"min values\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "#%%\n",
        "plt.plot(adam_optimizer.max_step_list,label=\"max values\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}